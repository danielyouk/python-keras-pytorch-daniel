{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 images belonging to 2 classes.\n",
      "Found 82 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.6053 - loss: 0.6776 - val_accuracy: 0.7805 - val_loss: 0.6496\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6007 - loss: 0.7027 - val_accuracy: 0.5854 - val_loss: 0.6488\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.4827 - loss: 0.7292 - val_accuracy: 0.5854 - val_loss: 0.6585\n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5669 - loss: 0.6556 - val_accuracy: 0.6585 - val_loss: 0.5882\n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6125 - loss: 0.6270 - val_accuracy: 0.5854 - val_loss: 0.6745\n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5657 - loss: 0.7032 - val_accuracy: 0.7927 - val_loss: 0.5293\n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6639 - loss: 0.5998 - val_accuracy: 0.7073 - val_loss: 0.5576\n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6611 - loss: 0.5955 - val_accuracy: 0.7683 - val_loss: 0.5465\n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.8423 - loss: 0.5255 - val_accuracy: 0.8171 - val_loss: 0.4979\n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.7524 - loss: 0.5190 - val_accuracy: 0.7927 - val_loss: 0.4972\n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.7158 - loss: 0.5637 - val_accuracy: 0.6463 - val_loss: 0.5724\n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.7999 - loss: 0.5162 - val_accuracy: 0.7683 - val_loss: 0.5336\n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.8126 - loss: 0.4911 - val_accuracy: 0.6463 - val_loss: 0.5790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3536a2e50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_loader = train_datagen.flow_from_directory('data/train', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "val_loader = val_datagen.flow_from_directory('data/test', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "\n",
    "# Load ResNet50 model without the top layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add the output layer with 2 classes\n",
    "predictions = layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Optionally freeze the layers of the base model to only train the new FC layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with SGD optimizer\n",
    "optimizer = optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping and model checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_loader,\n",
    "    epochs=50,\n",
    "    validation_data=val_loader,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
